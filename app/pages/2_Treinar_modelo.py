# Este arquivo implementa a p√°gina de treinamento de modelos da aplica√ß√£o
# Permite ao usu√°rio carregar dados, selecionar features, treinar diferentes 
# tipos de modelos de machine learning e visualizar m√©tricas de performance

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
import os
import sys
from datetime import datetime
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import messages as msn
import metrics as met
from models import ModelTypes, AutoWOEEncoder, BetaCalibratedClassifier
from config.config import set_page_config
set_page_config()

def get_features_and_target(data):
    """
    Fun√ß√£o para extrair features e vari√°vel target dos dados carregados
    
    Args:
        data: Arquivo Excel carregado pelo usu√°rio
        
    Returns:
        X: DataFrame com as features selecionadas
        y: Serie com a vari√°vel target
    """
    X, y = None, None
    if data is None:
        # Se nenhum dado for carregado, retorna None
        pass
    else:
        # Configura o layout em duas colunas
        col1, col2 = st.columns(2)
        #st.write("Carregando dados...")
        df = pd.read_excel(data)
        col1.write("Visualiza√ß√£o da sua base de dados (30 linhas)")
        col1.dataframe(df.head(30))
        cols = df.columns.tolist()

        # Assume por padr√£o que todas as colunas exceto a √∫ltima s√£o features
        # e a √∫ltima coluna √© o target
        feats_list, target_list = cols[:-1], cols[-1]

        # Permite ao usu√°rio confirmar ou modificar as features selecionadas
        features = col2.multiselect(label="Verifique que essas s√£o as vari√°veis de treino",
                                    options=cols, default=feats_list)
        # Permite ao usu√°rio confirmar ou modificar a vari√°vel target
        target = col2.multiselect(
            label="Verifique que esse √© seu alvo de treino",
            options=cols,
            default=target_list,
            max_selections=1)

        # Verifica se as sele√ß√µes s√£o v√°lidas:
        # - Features e target n√£o se sobrep√µem
        # - Exatamente um target foi selecionado
        exclusive = set(features).intersection(target) == set()
        has_target = len(target) == 1
        if exclusive & has_target:
            col2.write("‚úÖ Sua escolha de covari√°veis e alvo est√£o boas.\n\n Pode ir em frente com o treino.")
            X, y = df[features], df[target[0]]
        else:
            col2.write("‚ùå Garanta que voc√™ escolheu apenas um alvo e que ele n√£o fa√ßa parte das vari√°veis de treino!")
    return X, y


def reset_model_state():
    """
    Fun√ß√£o para limpar o estado do modelo quando uma nova sele√ß√£o √© feita
    Remove vari√°veis do session_state relacionadas ao modelo treinado
    """
    # Remove as vari√°veis de estado que armazenam informa√ß√µes do modelo atual
    for key in ['is_fit', 'model', 'features']:
        if key in st.session_state:
            del st.session_state[key]

def initialize_model_history():
    """
    Inicializa o hist√≥rico de modelos no session_state se n√£o existir
    """
    # Cria uma lista vazia para armazenar o hist√≥rico de modelos se ainda n√£o existir
    if 'model_history' not in st.session_state:
        st.session_state['model_history'] = []

def add_model_to_history(model_name, metrics_dict, features_used, model_wrapper):
    """
    Adiciona um modelo treinado ao hist√≥rico
    
    Args:
        model_name: Nome do modelo (ex: 'Regress√£o Log√≠stica')
        metrics_dict: Dicion√°rio com as m√©tricas do modelo
        features_used: Lista de features utilizadas no treino
        model_wrapper: O objeto model_wrapper completo para uso futuro
    """
    # Garante que o hist√≥rico esteja inicializado
    initialize_model_history()
    
    # Criando registro do modelo com timestamp atual e m√©tricas
    model_record = {
        'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'model_name': model_name,
        'roc_auc_train': metrics_dict['roc_auc_train'],
        'roc_auc_test': metrics_dict['roc_auc_test'],
        'ks_train': metrics_dict['ks_train'],
        'ks_test': metrics_dict['ks_test'],
        'features_count': len(features_used),
        'features_used': list(features_used),
        'model_wrapper': model_wrapper  # Salvando o model_wrapper completo
    }
    
    # Adicionando ao hist√≥rico
    st.session_state['model_history'].append(model_record)

def clear_model_history():
    """
    Limpa todo o hist√≥rico de modelos
    """
    # Reseta o hist√≥rico para uma lista vazia
    st.session_state['model_history'] = []

def display_metrics_explanation():
    """
    Exibe explica√ß√µes sobre as m√©tricas ROC AUC e KS Score
    """
    # Informa√ß√µes did√°ticas sobre as m√©tricas utilizadas
    st.markdown("""
    **ROC AUC (Area Under the Receiver Operating Characteristic Curve):** √â uma m√©trica que mede a capacidade de um modelo de classifica√ß√£o de distinguir entre duas classes (por exemplo, "bom pagador" e "mau pagador"). O valor da ROC AUC representa a probabilidade de um caso positivo aleat√≥rio ter uma pontua√ß√£o de risco maior do que um caso negativo aleat√≥rio. Os valores variam entre 0.5 (desempenho equivalente ao acaso) e 1 (desempenho perfeito).

    **KS Score (Kolmogorov-Smirnov):** √â outra m√©trica para avaliar o poder de separa√ß√£o de um modelo de classifica√ß√£o. Embora esteja sendo gradualmente substitu√≠da, √© uma m√©trica tradicionalmente muito utilizada na ind√∫stria de cr√©dito no Brasil.

    **A diferencia√ß√£o entre (treino) e (teste) refere-se aos conjuntos de dados utilizados:**

    - **ROC AUC (treino) e KS Score (treino):** Medem o desempenho do modelo nos mesmos dados que foram usados para cri√°-lo e trein√°-lo.

    - **ROC AUC (teste) e KS Score (teste):** Avaliam o desempenho do modelo em dados que n√£o foram utilizados durante o treinamento, oferecendo uma perspectiva sobre a capacidade de generaliza√ß√£o do modelo.
    """)

def display_model_history():
    """
    Exibe o hist√≥rico de modelos treinados em formato de tabela
    """
    # Garante que o hist√≥rico est√° inicializado
    initialize_model_history()
    
    # Verifica se h√° modelos no hist√≥rico
    if len(st.session_state['model_history']) == 0:
        st.info("Nenhum modelo foi treinado ainda. Treine um modelo para ver o hist√≥rico.")
        return
    
    # Convertendo hist√≥rico para DataFrame para melhor visualiza√ß√£o
    df_history = pd.DataFrame(st.session_state['model_history'])
    
    # Reorganizando colunas para melhor visualiza√ß√£o
    df_display = df_history[['timestamp', 'model_name', 'roc_auc_train', 'roc_auc_test', 
                           'ks_train', 'ks_test', 'features_count']].copy()
    
    # Renomeando colunas para melhor apresenta√ß√£o
    df_display.columns = ['Data/Hora', 'Modelo', 'ROC AUC (Treino)', 'ROC AUC (Teste)', 
                         'KS (Treino)', 'KS (Teste)', 'Qtd Features']
    
    # Formatando valores num√©ricos para melhor legibilidade
    for col in ['ROC AUC (Treino)', 'ROC AUC (Teste)']:
        df_display[col] = df_display[col].round(4)
    
    for col in ['KS (Treino)', 'KS (Teste)']:
        df_display[col] = df_display[col].round(2)
    
    # Exibe a tabela de hist√≥rico
    st.write("### üìä Hist√≥rico de Modelos Treinados")
    st.dataframe(df_display, use_container_width=True)
    
    # Adicionar explica√ß√£o das m√©tricas logo ap√≥s a tabela do hist√≥rico
    display_metrics_explanation()
    
    # Gr√°fico comparativo de modelos (apenas se houver mais de um modelo)
    if len(df_history) > 1:
        st.write("### üìà Compara√ß√£o de Performance")
        
        # Cria um gr√°fico interativo com Plotly
        fig = go.Figure()
        
        # Adiciona linha para ROC AUC Teste
        fig.add_trace(go.Scatter(
            x=list(range(len(df_history))),
            y=df_history['roc_auc_test'],
            mode='lines+markers',
            name='ROC AUC (Teste)',
            text=df_history['model_name'],
            hovertemplate='%{text}<br>ROC AUC: %{y:.4f}<extra></extra>'
        ))
        
        # Adiciona linha para KS Teste (eixo Y secund√°rio)
        fig.add_trace(go.Scatter(
            x=list(range(len(df_history))),
            y=df_history['ks_test'],
            mode='lines+markers',
            name='KS Score (Teste)',
            yaxis='y2',  # Usar segundo eixo Y
            text=df_history['model_name'],
            hovertemplate='%{text}<br>KS: %{y:.2f}<extra></extra>'
        ))
        
        # Configura√ß√£o do layout com dois eixos Y
        fig.update_layout(
            template="plotly_dark",
            title="Evolu√ß√£o da Performance dos Modelos",
            xaxis_title='Ordem de Treinamento',
            yaxis=dict(title='ROC AUC', side='left'),
            yaxis2=dict(title='KS Score', side='right', overlaying='y'),
            legend=dict(
                orientation="h",
                y=-0.2,
                x=0.5,
                xanchor="center",
                yanchor="top"
            )
        )
        
        # Exibe o gr√°fico de compara√ß√£o
        st.plotly_chart(fig, use_container_width=True)

def get_model_display_name(model_type):
    """
    Converte nomes internos dos modelos para nomes de exibi√ß√£o na interface
    """
    if model_type == ModelTypes.KNN:
        return "Regress√£o Linear"
    return model_type

if __name__ == '__main__':
    # Inicializar hist√≥rico de modelos
    initialize_model_history()

    # Exibe a mensagem de boas-vindas/instru√ß√µes
    st.write(msn.treino)
    
    # Inicializa vari√°veis para armazenar os dados de treino e valida√ß√£o
    X_train, X_val = None, None
    
    # Interface para upload do arquivo com os dados
    df = st.file_uploader("Envie seu arquivo para treino", type=['xlsx'], accept_multiple_files=False)
    
    # Extrai features e target dos dados carregados
    X, y = get_features_and_target(df)

    if X is not None:
        # Marca no session_state que h√° dados dispon√≠veis
        st.session_state['has_data'] = True
        if X is not None and y is not None:
            # Remove linhas onde y √© NaN para evitar problemas no treinamento
            mask = ~y.isna()
            X = X[mask]
            y = y[mask]
            if y.isna().sum() > 0:
                st.warning(f"Foram removidas {y.isna().sum()} linhas com alvo (y) nulo.")
            
            # Checagem se ainda h√° dados suficientes ap√≥s remover valores nulos
            if len(X) == 0 or len(y) == 0:
                st.error("N√£o h√° dados suficientes para treinar o modelo ap√≥s remover valores nulos. Verifique seu arquivo de entrada.")
                X_train = X_val = y_train = y_val = None
            else:
                # Divide os dados em treino e valida√ß√£o (70% / 30%)
                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, stratify=y, random_state=123)

    # Se√ß√£o de Hist√≥rico - antes da sele√ß√£o do modelo
    st.write("---")
    # Layout com tr√™s colunas para os bot√µes de hist√≥rico
    col_hist1, col_hist2, col_hist3 = st.columns([2, 1, 1])
    
    # Bot√£o para mostrar/ocultar o hist√≥rico
    with col_hist1:
        if st.button("üìà Ver Hist√≥rico de Modelos"):
            st.session_state['show_history'] = not st.session_state.get('show_history', False)
    
    # Bot√£o para atualizar o hist√≥rico
    with col_hist2:
        if st.button("üîÑ Atualizar Hist√≥rico", type="primary"):
            st.rerun()
    
    # Bot√£o para limpar o hist√≥rico
    with col_hist3:
        if st.button("üóëÔ∏è Limpar Hist√≥rico", type="secondary"):
            clear_model_history()
            st.success("Hist√≥rico limpo com sucesso!")
            st.rerun()
    
    # Exibe o hist√≥rico de modelos se o bot√£o foi acionado
    if st.session_state.get('show_history', False):
        display_model_history()
    
    st.write("---")

    # Sele√ß√£o do modelo a ser treinado com nomes mais amig√°veis
    model_types = [val for key, val in ModelTypes.__dict__.items() if not key.startswith('__')]
    display_names = [get_model_display_name(model_type) for model_type in model_types]
    
    model_choice = st.selectbox(
        label="Selecione o modelo para treinar",
        options=["Selecionar..."] + display_names,
        index=0,
        key="model_choice",
        on_change=reset_model_state  # Reseta o estado quando o usu√°rio muda de modelo
    )

    # Configura√ß√£o dos modelos dispon√≠veis
    # Usando o padr√£o match/case do Python 3.10+
    match model_choice:
        case ModelTypes.LOG_REG:
            # Regress√£o Log√≠stica com regulariza√ß√£o L1 (Lasso)
            base_model = LogisticRegression(class_weight='balanced', penalty='l1', C=0.01, solver='liblinear')

        case ModelTypes.LGBM:
            # LightGBM - algoritmo de gradient boosting eficiente
            from lightgbm import LGBMClassifier
            base_model = LGBMClassifier(n_estimators=300, learning_rate=0.007, reg_alpha=0.5, reg_lambda=0.5,  random_state=123)

        case "Regress√£o Linear":
            # Regress√£o Linear calibrada para fornecer probabilidades
            from sklearn.linear_model import RidgeClassifier
            from sklearn.calibration import CalibratedClassifierCV
            
            # Usamos CalibratedClassifierCV para adicionar funcionalidade predict_proba
            # ao RidgeClassifier que naturalmente n√£o a possui
            ridge_model = RidgeClassifier(alpha=1.0, class_weight='balanced', random_state=123)
            base_model = CalibratedClassifierCV(ridge_model, method='sigmoid', cv=3)

        case ModelTypes.XGB:
            # XGBoost - implementa√ß√£o popular de gradient boosting
            from xgboost import XGBClassifier
            base_model = XGBClassifier(learning_rate=0.08, n_estimators=125, max_depth=6, colsample_bytree=0.9,gamma=0.5,
                                  min_child_weight=1,subsample=0.8)

        case ModelTypes.ANN:
            # Rede Neural Artificial - implementa√ß√£o do scikit-learn
            from sklearn.neural_network import MLPClassifier
            base_model = MLPClassifier((4, 8, 4), random_state=123)
        case _:
            # Caso nenhum modelo seja selecionado
            base_model = None

    # Se um modelo foi selecionado e h√° dados dispon√≠veis
    if base_model is not None and st.session_state.get('has_data'):
        if X_train is None:
            print("Selecione seus dados antes de treinar o modelo")
        else:
            # Tratando valores nulos antes do processamento
            X_train = X_train.fillna(0)
            X_val = X_val.fillna(0)
            
            # Criando pipeline compat√≠vel com todos os modelos
            if model_choice in [ModelTypes.XGB, ModelTypes.ANN]:
                # Para XGBoost e ANN, usamos uma abordagem em duas etapas
                # para evitar problemas de compatibilidade com o pipeline do sklearn
                encoder = AutoWOEEncoder()
                scaler = StandardScaler().set_output(transform="pandas")
                
                # Pipeline para pr√©-processamento apenas
                preprocess_pipeline = Pipeline([
                    ('auto_woe_encoder', encoder),
                    ('scaler', scaler)
                ])
                
                # Aplicar pr√©-processamento aos dados
                X_train_processed = preprocess_pipeline.fit_transform(X_train, y_train)
                X_val_processed = preprocess_pipeline.transform(X_val)
                
                # Wrapper que cont√©m tanto o pipeline de pr√©-processamento quanto o modelo
                model_wrapper = {
                    'type': 'two_step',
                    'preprocess': preprocess_pipeline,
                    'model': base_model
                }
            else:
                # Para outros modelos (mais compat√≠veis), usamos o pipeline padr√£o
                # que combina pr√©-processamento e modelo em um √∫nico objeto
                model_wrapper = {
                    'type': 'pipeline',
                    'pipeline': Pipeline([
                        ('auto_woe_encoder', AutoWOEEncoder()),
                        ('scaler', StandardScaler().set_output(transform="pandas")),
                        ('model', base_model)
                    ])
                }

            # Bot√£o para iniciar o treinamento do modelo
            fit = st.button("Treinar modelo (pode levar alguns minutos)")
            if fit:
                try:
                    # Treinar o modelo conforme o tipo de wrapper
                    if model_wrapper['type'] == 'two_step':
                        # Treinar o modelo separadamente ap√≥s pr√©-processamento
                        model_wrapper['model'].fit(X_train_processed, y_train)
                        is_fit = True
                    else:
                        # Treinar o pipeline completo
                        model_wrapper['pipeline'].fit(X_train, y_train)
                        is_fit = True
                    
                    st.write("Modelo treinado!")
                    
                    # Salvar no session_state para uso posterior
                    st.session_state['is_fit'] = True
                    st.session_state['model_wrapper'] = model_wrapper
                    st.session_state['features'] = X_train.columns
                    
                    # Calcular m√©tricas imediatamente ap√≥s o treinamento
                    if model_wrapper['type'] == 'two_step':
                        # Para modelos de duas etapas, precisamos aplicar o pr√©-processamento
                        y_probs = model_wrapper['model'].predict_proba(X_val_processed)[:, 1]
                        y_probs_treino = model_wrapper['model'].predict_proba(X_train_processed)[:, 1]
                    else:
                        # Para pipeline padr√£o, podemos passar os dados diretamente
                        y_probs = model_wrapper['pipeline'].predict_proba(X_val)[:, 1]
                        y_probs_treino = model_wrapper['pipeline'].predict_proba(X_train)[:, 1]

                    # Calcula m√©tricas de performance
                    roc_auc_teste = met.roc_auc(y_val, y_probs)
                    ks_teste = met.ks_score(y_val, y_probs)
                    roc_auc_train = met.roc_auc(y_train, y_probs_treino)
                    ks_train = met.ks_score(y_train, y_probs_treino)

                    # Adicionar ao hist√≥rico de modelos
                    metrics_dict = {
                        'roc_auc_train': roc_auc_train,
                        'roc_auc_test': roc_auc_teste,
                        'ks_train': ks_train,
                        'ks_test': ks_teste
                    }
                    add_model_to_history(model_choice, metrics_dict, X_train.columns, model_wrapper)
                    
                    # Confirma√ß√£o visual para o usu√°rio
                    st.success(f"‚úÖ Modelo {model_choice} adicionado ao hist√≥rico!")
                    st.info("üí° Clique em 'Atualizar Hist√≥rico' para ver as mudan√ßas se o hist√≥rico estiver aberto.")
                    
                    # Adicionar explica√ß√µes espec√≠ficas para cada modelo
                    if model_choice == ModelTypes.LOG_REG:
                        st.markdown("""
                        ### Regress√£o Log√≠stica
                        **Vantagens**: √â um modelo muito r√°pido, que consome poucos recursos computacionais e √© extremamente f√°cil de interpretar. Os coeficientes de cada vari√°vel mostram de forma clara e direta como elas influenciam a previs√£o, o que √© excelente para explicar os resultados e gerar insights de neg√≥cio.

                        **Desvantagens**: Sua principal fraqueza √© a incapacidade de capturar rela√ß√µes complexas e n√£o-lineares nos dados. O modelo assume uma fronteira de decis√£o linear, o que limita seu poder preditivo em problemas mais complexos, onde modelos mais modernos geralmente apresentam performance superior.
                        """)
                    elif model_choice == ModelTypes.LGBM:
                        st.markdown("""
                        ### LightGBM
                        **Vantagens**: Sua maior vantagem √© a velocidade de treinamento e o baixo uso de mem√≥ria. Ele √© significativamente mais r√°pido que seus concorrentes (como o XGBoost) em grandes volumes de dados, permitindo itera√ß√µes e experimentos muito mais √°geis. Mant√©m um alt√≠ssimo poder preditivo.

                        **Desvantagens**: Em datasets pequenos (com poucos milhares de linhas), ele √© mais propenso a overfitting (se ajustar demais aos dados de treino e generalizar mal). A grande quantidade de hiperpar√¢metros, embora flex√≠vel, pode tornar sua otimiza√ß√£o um processo complexo.
                        """)
                    elif model_choice == "Regress√£o Linear":
                        st.markdown("""
                        ### Regress√£o Linear
                        **Vantagens**: √â o modelo mais simples e intuitivo para prever valores num√©ricos cont√≠nuos. √â muito r√°pido para treinar e seus resultados s√£o totalmente interpret√°veis, permitindo entender exatamente quanto cada vari√°vel contribui para a previs√£o final.

                        **Desvantagens**: Sua maior limita√ß√£o √© assumir que a rela√ß√£o entre as vari√°veis √© puramente linear. Ele n√£o consegue modelar curvas ou intera√ß√µes complexas, al√©m de ser muito sens√≠vel a outliers (valores extremos), o que o torna inadequado para a maioria dos problemas do mundo real que buscam m√°xima precis√£o.
                        """)
                    elif model_choice == ModelTypes.XGB:
                        st.markdown("""
                        ### XGBoost (Extreme Gradient Boosting)
                        **Vantagens**: √â famoso por seu alt√≠ssimo poder preditivo e robustez. Frequentemente, √© o modelo que apresenta os melhores resultados em competi√ß√µes de Machine Learning com dados estruturados (tabelas). Possui mecanismos internos de regulariza√ß√£o que ajudam a controlar o overfitting.

                        **Desvantagens**: Seu principal ponto fraco √© o alto custo computacional. Ele tende a ser mais lento para treinar e consumir mais mem√≥ria do que alternativas como o LightGBM. A sintonia fina de seus diversos hiperpar√¢metros tamb√©m pode ser um processo demorado e complexo.
                        """)
                    elif model_choice == ModelTypes.ANN:
                        st.markdown("""
                        ### Rede Neural
                        **Vantagens**: Tem uma capacidade incompar√°vel de aprender padr√µes muito complexos e n√£o-lineares, sendo o modelo de escolha para dados n√£o estruturados como imagens, √°udio e texto. Quando bem treinada e com dados suficientes, pode atingir o maior poder preditivo entre todos os modelos.

                        **Desvantagens**: S√£o modelos "caixa-preta" (black box), ou seja, √© extremamente dif√≠cil entender o porqu√™ de suas decis√µes. Exigem um volume massivo de dados, alto custo computacional (tempo e hardware potentes) e sua arquitetura e ajuste de hiperpar√¢metros s√£o notoriamente complexos.
                        """)
                except Exception as e:
                    # Tratamento de erros durante o treinamento
                    st.error(f"Erro ao treinar o modelo: {str(e)}")
                    st.exception(e)

    # Se√ß√£o de diagn√≥stico - exibida apenas se um modelo foi treinado
    if st.session_state.get('is_fit') is not None and st.session_state.get('has_data'):
        model_wrapper = st.session_state['model_wrapper']
        st.write("---")
        
        # T√≠tulo do diagn√≥stico
        st.write("# Diagn√≥stico do modelo")
        
        if X_val is None or X_train is None:
            st.write("D√™ upload de base de treino novamente")
        else:
            try:
                # Fazer predi√ß√µes de acordo com o tipo de modelo
                if model_wrapper['type'] == 'two_step':
                    # Para modelos de duas etapas, aplicamos o pr√©-processamento primeiro
                    X_val_processed = model_wrapper['preprocess'].transform(X_val)
                    X_train_processed = model_wrapper['preprocess'].transform(X_train)
                    
                    y_probs = model_wrapper['model'].predict_proba(X_val_processed)[:, 1]
                    y_probs_treino = model_wrapper['model'].predict_proba(X_train_processed)[:, 1]
                else:
                    # Para pipeline padr√£o, podemos passar os dados diretamente
                    y_probs = model_wrapper['pipeline'].predict_proba(X_val)[:, 1]
                    y_probs_treino = model_wrapper['pipeline'].predict_proba(X_train)[:, 1]
                
                # Calcular m√©tricas de performance novamente
                roc_auc_teste = met.roc_auc(y_val, y_probs)
                ks_teste = met.ks_score(y_val, y_probs)
                roc_auc_train = met.roc_auc(y_train, y_probs_treino)
                ks_train = met.ks_score(y_train, y_probs_treino)
                
                # Layout para m√©tricas e explica√ß√µes lado a lado
                metrics_col, explanation_col = st.columns([1, 1])
                
                # Coluna esquerda: Exibi√ß√£o das m√©tricas
                with metrics_col:
                    st.subheader("M√©tricas de Performance")
                    col1, col2 = st.columns(2)
                    
                    # Exibir m√©tricas formatadas com a fun√ß√£o metric()
                    col1.metric(label="ROC AUC (teste)", value=f"{round(roc_auc_teste, 4)}")
                    col1.metric(label="KS Score (teste)", value=f"{round(ks_teste, 2)}")

                    col2.metric(label="ROC AUC (treino)", value=f"{round(roc_auc_train, 4)}")
                    col2.metric(label="KS Score (treino)", value=f"{round(ks_train, 2)}")
                
                # Coluna direita: Explica√ß√£o das m√©tricas
                with explanation_col:
                    st.subheader("üìö O que significam estas m√©tricas?")
                    display_metrics_explanation()

                # Se√ß√£o de visualiza√ß√µes gr√°ficas
                st.write("### Visualiza√ß√µes")
                
                # Gr√°fico 1: Curva ROC
                # Calcula pontos para a curva ROC
                fpr, tpr = met.roc_curve(y_val, y_probs)
                fpr_train, tpr_train = met.roc_curve(y_train, y_probs_treino)

                # Layout com gr√°fico e explica√ß√£o lado a lado
                roc_graph_col, roc_explanation_col = st.columns([3, 2])
                
                # Coluna esquerda: Gr√°fico da Curva ROC
                with roc_graph_col:
                    fig = go.Figure()
                    # Adiciona curva ROC para dados de teste
                    fig.add_trace(go.Scatter(x=fpr.round(3), y=tpr.round(3),
                                                mode='lines',
                                                name='ROC (Teste)',
                                                hovertemplate='FPR: %{x}, TPR: %{y} <extra></extra>'))
                    # Adiciona curva ROC para dados de treino
                    fig.add_trace(go.Scatter(x=fpr_train.round(3), y=tpr_train.round(3),
                                                mode='lines',
                                                name='ROC (Train)',
                                                hovertemplate='FPR: %{x}, TPR: %{y} <extra></extra>'))
                    # Adiciona linha de refer√™ncia (baseline aleat√≥rio)
                    fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1],
                                                mode='lines',
                                                line=dict(dash='dot'),
                                                name='Baseline aleat√≥rio'))

                    # Configura√ß√£o do layout do gr√°fico
                    fig.update_layout(template="plotly_dark",
                                        title="Curva ROC",
                                        xaxis_title='Taxa de falsos positivos (FPR)',
                                        yaxis_title='Taxa de positivos verdadeiros (TPR)',
                                        legend=dict(
                                            orientation="h",
                                            y=-0.2,
                                            x=0.5,
                                            xanchor="center",
                                            yanchor="top"
                                        ))

                    # Exibe o gr√°fico da curva ROC
                    st.plotly_chart(fig, theme=None, use_container_width=True)
                
                # Coluna direita: Explica√ß√£o da Curva ROC
                with roc_explanation_col:
                    st.subheader("üìä Entendendo a Curva ROC")
                    st.markdown("""
                    **Curva ROC** avalia a performance de um modelo preditivo, mostrando o qu√£o bem ele consegue separar dois grupos (por exemplo, bons e maus pagadores). O objetivo √© ter uma curva que se aproxime o m√°ximo poss√≠vel do canto superior esquerdo.

                    **Linhas azul e vermelha (ROC)**: Mostram o desempenho do modelo. O objetivo √© que elas se afastem da linha pontilhada e cheguem o mais perto poss√≠vel do canto superior esquerdo.

                    **Linha azul (Teste)**: √â a mais importante, pois mostra o desempenho do modelo com dados novos, como aconteceria na vida real.

                    **Linha pontilhada (Baseline)**: Representa um palpite ou um chute. O modelo precisa ser melhor do que isso para ser √∫til.
                    """)

                # Gr√°fico 2: Curvas de Erro
                st.subheader("Curvas de Erro")
                
                # Layout com gr√°fico e explica√ß√£o lado a lado
                error_graph_col, error_explanation_col = st.columns([3, 2])
                
                # Coluna esquerda: Gr√°fico de Curvas de Erro
                with error_graph_col:
                    # Calcula taxas de erro para diferentes thresholds
                    fpr, fnr, thresh = met.false_positive_negative_rates(y_val, y_probs)

                    fig = go.Figure()
                    # Adiciona curva de falsos positivos
                    fig.add_trace(go.Scatter(x=thresh.round(3), y=fpr.round(3),
                                                mode='lines',
                                                name='Taxa de falsos positivos (FPR)',
                                                hovertemplate='Thresh: %{x}, FPR: %{y}<extra></extra>'))
                    # Adiciona curva de falsos negativos
                    fig.add_trace(go.Scatter(x=thresh.round(3), y=fnr.round(3),
                                                mode='lines',
                                                name='Taxa de falsos negativos (FNR)',
                                                hovertemplate='Thresh: %{x}, FNR: %{y}<extra></extra>'))

                    # Configura√ß√£o do layout do gr√°fico
                    fig.update_xaxes(range=[0.0, 1.0])
                    fig.update_layout(template="plotly_dark",
                                        title="Curvas de falsos positivos / negativos (somente conjunto de teste)",
                                        xaxis_title='Limiar de cutoff (threshold)',
                                        legend=dict(
                                            orientation="h",
                                            y=-0.2,
                                            x=0.5,
                                            xanchor="center",
                                            yanchor="top"
                                        ))

                    # Exibe o gr√°fico de curvas de erro
                    st.plotly_chart(fig, theme=None, use_container_width=True)
                
                # Coluna direita: Explica√ß√£o das Curvas de Erro
                with error_explanation_col:
                    st.subheader("üìâ Entendendo as Curvas de Erro")
                    st.markdown("""
                    Este gr√°fico ajuda a decidir qual "nota de corte" (ou threshold) usar para tomar uma decis√£o com o modelo. A "nota de corte" √© a regra que define, por exemplo, a partir de qual pontua√ß√£o de risco um cliente ter√° o cr√©dito negado. O gr√°fico mostra como a escolha dessa regra afeta dois tipos de erro.

                    **Linha azul (Falsos positivos)**: √â o erro de "alarme falso" (negar cr√©dito a um bom cliente).

                    **Linha vermelha (Falsos negativos)**: √â o erro de "deixar passar" (aprovar cr√©dito para um mau cliente).

                    A escolha da melhor "nota de corte" (o ponto no eixo horizontal) depende de qual desses dois erros √© pior para o seu neg√≥cio, pois n√£o √© poss√≠vel zerar ambos ao mesmo tempo.
                    """)

                # Se√ß√£o de interpretabilidade - dispon√≠vel apenas para regress√£o log√≠stica
                if model_choice == ModelTypes.LOG_REG:
                    st.subheader("Interpretabilidade do modelo")
                    
                    # Layout com gr√°fico e explica√ß√£o lado a lado
                    coef_graph_col, coef_explanation_col = st.columns([3, 2])
                    
                    # Coluna esquerda: Gr√°fico de coeficientes
                    with coef_graph_col:
                        # Obter o modelo correto dependendo do tipo de wrapper
                        if model_wrapper['type'] == 'two_step':
                            model_obj = model_wrapper['model']
                        else:
                            model_obj = model_wrapper['pipeline'].named_steps['model']
                        
                        # Verificar se o modelo tem coeficientes dispon√≠veis
                        if hasattr(model_obj, 'coef_'):
                            # Extrai os coeficientes e cria um DataFrame para visualiza√ß√£o
                            coefs = model_obj.coef_
                            aux = pd.DataFrame({'var': X_train.columns, 'coef': coefs[0]}).sort_values('coef', ascending=True).reset_index(drop=True)
                            
                            # Cria um gr√°fico de barras horizontais com os coeficientes
                            fig, ax = plt.subplots(figsize=(5,6))
                            ax.barh(aux.index, aux['coef'])
                            ax.set_yticks(aux.index, aux['var'])
                            ax.set_title('Coeficientes da regress√£o log√≠stica')
                            ax.grid()
                            ax.set_facecolor('#0C1017')
                            st.pyplot(fig)
                        else:
                            # Mensagem se os coeficientes n√£o estiverem dispon√≠veis
                            st.warning("N√£o foi poss√≠vel acessar os coeficientes do modelo.")
                    
                    # Coluna direita: Explica√ß√£o dos coeficientes
                    with coef_explanation_col:
                        st.subheader("üìä Entendendo os Coeficientes")
                        st.markdown("""
                        Este gr√°fico mostra a **import√¢ncia e o impacto** de cada vari√°vel no modelo de regress√£o log√≠stica:

                        **Valores positivos** (barras para a direita): Indicam que a vari√°vel **aumenta** a chance de um resultado positivo (ex: inadimpl√™ncia).

                        **Valores negativos** (barras para a esquerda): Indicam que a vari√°vel **diminui** a chance de um resultado positivo.

                        **Tamanho da barra**: Quanto maior o valor absoluto (comprimento da barra), maior o impacto da vari√°vel na decis√£o do modelo.

                        Isso permite identificar quais caracter√≠sticas mais contribuem para o risco e quais s√£o "protetivas" na sua an√°lise.
                        """)
                        
            except Exception as e:
                # Tratamento de erros na se√ß√£o de diagn√≥stico
                st.error(f"Erro ao gerar diagn√≥stico: {str(e)}")
                st.exception(e)
